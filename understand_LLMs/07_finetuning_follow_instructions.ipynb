{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning to follow instructions\n",
    "\n",
    "Instruction fine-tuning is one of the main techniques behind developing LLMs for chatbot apps, personal assistants, and other conversational\n",
    "\n",
    "Herer, we focus on improving the LLM's ability to follow instructions and generate desired response. Preparing the dataset is a key aspect of instruction fine-tuning\n",
    "\n",
    "The dataset consists of 1,100 instruction-response pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries\", len(data))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"example entry:\\n\", data[999])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various methods to format the entries for LLMs. The following figure illustrates 2 different example formats, often referred to as **prompt styles** used in training of notable LLMs such as Alpaca and Phi-3\n",
    "\n",
    "![prompt_style](prompt_style.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = (\n",
    "        f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    )\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f'\\n\\n### Response:\\n{data[50][\"output\"]}'\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f'\\n\\n### Response:\\n{data[50][\"output\"]}'\n",
    "print(model_input + desired_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Testing set length: 110\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Testing set length:\", len(test_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizing data into training batches\n",
    "\n",
    "we learn how to efficiently pad the data samples to equal lengths so we can assemble multiple instruction examples in a batch\n",
    "In the previous chapter, the training batches were created automatically by the PyTorch `DataLoader` class, which employes the default collate function to combine lists of samples into batches.\n",
    "A collate function is responsible for taking a list of individual data samples and merging hem into a single batch that can be processed efficiently by the model during training\n",
    "However the batching process for instruction fine-tuning is a bit more involved and requires us to create our own custom colloate function that will later plug into the `DataLoader` \n",
    "\n",
    "![batching process instruction dataset](batching_process.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_text = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_text.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_text[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "# For padding we can append the token ID corresponding to `<|endoftext|>` to the pretokenized inputs directly.\n",
    "\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom collate fucntion that we can pass to the dataloader. It pads the training examples in each batch to the same length while allowing different batches to have different lenghts. This approach minimizes unnecessary padding by only extending sequences to match the longest one in each batch, not the whole dataset\n",
    "\n",
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    input_lst = []\n",
    "    \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        \n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # removes extra padded token added earlier\n",
    "        input_lst.append(inputs)\n",
    "    \n",
    "    inputs_tensor = torch.stack(input_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4],\n",
      "        [    6, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8n/tlk756jx44lbb6m66gsbw03m0000gn/T/ipykernel_41892/81555748.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = torch.tensor(inputs[1:])\n"
     ]
    }
   ],
   "source": [
    "# we modify our custom collate function to return the tarket token IDs in addition to the input token IDs.\n",
    "# Similar to the processs we used to pretrain an LLM, the target token IDs match the input token IDs but are shifted one position to the right.\n",
    "# It allows the LLM o learn how to predict the next token in a sequence\n",
    "\n",
    "def custom_collate_draft2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        \n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  \n",
    "        targets = torch.tensor(inputs[1:])\n",
    "        \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "        \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    \n",
    "    return inputs_tensor, targets_tensor\n",
    "\n",
    "inputs, targets = custom_collate_draft2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we assign a `-100` placeholder value to all padding tokens. This special value allows us to exclude thes padding tokens from contributing to the training loss calculation, ensuring that only meaningful data influences model learning.\n",
    "When fine tuning for classification, we did not have to worry about this since we only trained the model based on the last output token\n",
    "However, we retain one end-of-text token, in the target list. Retaining it allows the LLM to learn when to generate an end-of-text token in response to instructions, which we use as an indicator that the generated response is complete.\n",
    "\n",
    "\n",
    "The defaualt setting of the cross entropy function in PyTorch is `cross_entropy(...,ignore_index=-100)`. This means that it ignores targets labeled with `-100`. We take advantage of this `ignore_index` to ignore the additional EOF (padding) tokens that we used to pad the training examples to have the same length in each batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,   # parameter to optionally limit the length of samples\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        \n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  \n",
    "        targets = torch.tensor(padded[1:])\n",
    "        \n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        \n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "            \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "        \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    \n",
    "    return inputs_tensor, targets_tensor\n",
    "\n",
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to masking out padding tokens, it is also common to mask out the target token IDs that correspond to the instruction. By doing so, the cross entropy loss is only computed for the generated response target IDs. Thus the model is trained to focus on generating accurate responses rather that memorizing  instructions, which can help reduce overfitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating data loaders for an instruction dataset\n",
    "\n",
    "Previously we moved the data onto the target device in the main training loop\n",
    "Having this as part of the collate function offers the advantage of performing this devie transfer process as a background porcess outside the training loop, preventing it from blocking the GPU during model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "device = \"cpu\"\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reuse the chosen device setting in `custom_collate_fn` when we plug it into the PyTorch `DataLoader` class, we use the `partial` function from Python's `functools` standard library to create a new version of the function with the device arg prefilled\n",
    "# additionally, we set the `allowed_max_length` to 1024 which truncates the data too the maximum context length supported by GPT-2 model\n",
    "\n",
    "from functools import partial\n",
    "custom_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a pretrained LLM\n",
    "\n",
    "We load the medium-sized model with 355 million parameters. The reason for this choice is that the 124-million parameter model is too limited in capacity to achieve statisfactory results. \n",
    "Specificall, smaller models lack the necessary capacity to learn and retain the intricated patters and nuanced behaviors required for high quality instruction following tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 10.6kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 808kiB/s]\n",
      "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 29.0kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [05:29<00:00, 4.30MiB/s] \n",
      "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 6.37MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 927k/927k [00:01<00:00, 810kiB/s]  \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 571kiB/s] \n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from chapter_04 import GPTModel\n",
    "from chapter_05 import load_weights_into_gpt\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size, \n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "from chapter_05 import generate, text_to_token_ids, token_ids_to_text\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning the LLM on instruction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.825894069671631\n",
      "Validation loss: 3.7619182586669924\n"
     ]
    }
   ],
   "source": [
    "from chapter_05 import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=5\n",
    "    )\n",
    "    val_loss = calc_loss_loader(\n",
    "        val_loader, model, device, num_batches=5\n",
    ")\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.103\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.945\n",
      "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.790\n",
      "Ep 1 (Step 000050): Train loss 0.662, Val loss 0.783\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.764\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.652, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.532, Val loss 0.729\n",
      "Ep 1 (Step 000075): Train loss 0.569, Val loss 0.729\n",
      "Ep 1 (Step 000080): Train loss 0.605, Val loss 0.725\n",
      "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.709\n",
      "Ep 1 (Step 000090): Train loss 0.562, Val loss 0.691\n",
      "Ep 1 (Step 000095): Train loss 0.500, Val loss 0.681\n",
      "Ep 1 (Step 000100): Train loss 0.502, Val loss 0.677\n",
      "Ep 1 (Step 000105): Train loss 0.564, Val loss 0.670\n",
      "Ep 1 (Step 000110): Train loss 0.555, Val loss 0.667\n",
      "Ep 1 (Step 000115): Train loss 0.508, Val loss 0.664\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.672\n",
      "Ep 2 (Step 000125): Train loss 0.451, Val loss 0.686\n",
      "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
      "Ep 2 (Step 000135): Train loss 0.404, Val loss 0.682\n",
      "Ep 2 (Step 000140): Train loss 0.410, Val loss 0.681\n",
      "Ep 2 (Step 000145): Train loss 0.369, Val loss 0.681\n",
      "Ep 2 (Step 000150): Train loss 0.381, Val loss 0.676\n",
      "Ep 2 (Step 000155): Train loss 0.412, Val loss 0.676\n",
      "Ep 2 (Step 000160): Train loss 0.415, Val loss 0.684\n",
      "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.686\n",
      "Ep 2 (Step 000170): Train loss 0.323, Val loss 0.682\n",
      "Ep 2 (Step 000175): Train loss 0.337, Val loss 0.670\n",
      "Ep 2 (Step 000180): Train loss 0.393, Val loss 0.658\n",
      "Ep 2 (Step 000185): Train loss 0.416, Val loss 0.659\n",
      "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.650\n",
      "Ep 2 (Step 000195): Train loss 0.330, Val loss 0.637\n",
      "Ep 2 (Step 000200): Train loss 0.310, Val loss 0.637\n",
      "Ep 2 (Step 000205): Train loss 0.352, Val loss 0.632\n",
      "Ep 2 (Step 000210): Train loss 0.367, Val loss 0.631\n",
      "Ep 2 (Step 000215): Train loss 0.396, Val loss 0.635\n",
      "Ep 2 (Step 000220): Train loss 0.301, Val loss 0.649\n",
      "Ep 2 (Step 000225): Train loss 0.349, Val loss 0.662\n",
      "Ep 2 (Step 000230): Train loss 0.294, Val loss 0.658\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in 40.91 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=0.00005, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, token_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq=5,\n",
    "    eval_iter=5, start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time) /60\n",
    "print(f\"Training completed in {execution_time:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chapter_05 import plot_losses\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, token_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "----------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "----------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    \n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instruction -fine-tuned LLMs such as chatbots are evaluated via multiple approaches:\n",
    "- Short-answer and multiple-choice benchmarks, such as Measuring Massive Multitask Language Understanding (MMLU) which test the general knowledge of a model\n",
    "- Human preference comparison to other LLMs such as LMSYS chatbot arean\n",
    "- Automated conversational benchmarks, where another LLM like GPT-4 is used to evaluate the responses, such as AlpacaEval\n",
    "\n",
    "## Conversational performance\n",
    "\n",
    "It refers to the ability of LLMs to engage in human-like communication by understanding context, nuance, and intent. It encompasses skills such as providing relevant and coherent responses, maintaining consistency, and adapting to different topics and styles of interaction\n",
    "\n",
    "\n",
    "To evaluate test set responses in an automated fashion, we utilize an exisiting instruction-fine-tuned 8-billion parameter Llama 3 model. This model can be run locally using the open source Ollama application\n",
    "**Ollama** is an efficient application for running LLMs on a laptop. It serves as a wrapper around the open source llama.cpp library which implements LLMs in pure C/C++ to maximize efficiency. \n",
    "However, Ollama is only a tool for generating text using LLMs (infernce) and does not support training or fine-tuning LLMs.\n",
    "\n",
    "The `llama3` in the `ollama run llama3` command refers to the instruction-fine-tuned 8-billion parameter Llama 3 model. Using Ollama with the llama3 model requires approxiamtely 16GB of RAM. You can try using a smaller model, such as the 3.8 billion parameter `phi3` model via `ollama run llama3` which only requires around 8GB of RAM\n",
    "\n",
    "For more powerful computers, you can also use the larger 70-billion parameter Llama3 model by replacing llama3 with `llana3:70b` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Ollama not running. Launch ollama before proceeding.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m ollama_running \u001b[39m=\u001b[39m check_if_running(\u001b[39m\"\u001b[39m\u001b[39mollama\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ollama_running:\n\u001b[0;32m---> 16\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m     17\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOllama not running. Launch ollama before proceeding.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOllama running:\u001b[39m\u001b[39m\"\u001b[39m, check_if_running(\u001b[39m\"\u001b[39m\u001b[39mollama\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Ollama not running. Launch ollama before proceeding."
     ]
    }
   ],
   "source": [
    "# Verify that the Ollama session is running\n",
    "\n",
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\n",
    "        \"Ollama not running. Launch ollama before proceeding.\"\n",
    ")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative to the ollama run command for interacting with the model is through itsREST API using Pythoh \n",
    "\n",
    "import urllib.request\n",
    "\n",
    "def query_model(  # shows how to use the API\n",
    "    prompt, \n",
    "    model=\"llama3\", \n",
    "    url=\"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        data=payload,\n",
    "        method=\"POST\"\n",
    "    )\n",
    "\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import json\n",
    "\n",
    "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an optional step that can be performed after instruction fine tuning: preference fine tuning. It is particularly useful for customizing a model to better align with specific user preferences,\n",
    "\n",
    "\n",
    "Parameter efficient fine tuning with LoRA (low-rank adaptation method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
