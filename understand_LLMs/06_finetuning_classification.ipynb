{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning for classification\n",
    "\n",
    "fine tune the LLm on a specific target task such as classifying text. The concrete example we examine is classifying text messages as \"spam\" or \"not spam\"\n",
    "2 main ways of fine tuning an LLM:\n",
    "- fine-tuning for classification\n",
    "- fine-tuning to follow instructions\n",
    "\n",
    "The most common ways to fine-tune LMs are **instruction fine-tuning** and **classification fine-tuning**.\n",
    "Instruction fine-tuning involves training a LM on a set of tasks using specific instructions to improve its ability to understand and execute tasks described in natural language prompts\n",
    "In classification fine-tuning, the model is trained to recognize a specific set of class labels. The key point is that a classification fine-tuned model is restricted to predicting classes it has encountered during its training\n",
    "\n",
    "In contrast to classification fine-tuned model, an instruction fine tuned model typically can undertake a broader range of tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping downlad and extraction \n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(\n",
    "    url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping downlad and extraction \")\n",
    "        return\n",
    "    \n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "        \n",
    "    \n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "            \n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\n",
    "    data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"]\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(\n",
    "        num_spam, random_state=123\n",
    "    )\n",
    "    balanced_df = pd.concat([\n",
    "        ham_subset, df[df[\"Label\"] == \"spam\"]\n",
    "    ])\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the \"string\" class labels \"ham\" and \"spam\" into integer class labels 0 and 1 \n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\":0, \"spam\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    \n",
    "    df = df.sample(\n",
    "        frac=1,random_state=123\n",
    "    ).reset_index(drop=True)\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "    \n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "    \n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dude how do you like the buff wind.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Tessy..pls do me a favor. Pls convey my birthd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Reminder: You have not downloaded the content ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Got what it takes 2 take part in the WRC Rally...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Shop till u Drop, IS IT YOU, either 10K, 5K, £...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>1</td>\n",
       "      <td>4mths half price Orange line rental &amp; latest c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>1</td>\n",
       "      <td>Thanks for the Vote. Now sing along with the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>1</td>\n",
       "      <td>IMPORTANT INFORMATION 4 ORANGE USER 0796XXXXXX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>1</td>\n",
       "      <td>Urgent! call 09066612661 from landline. Your c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>0</td>\n",
       "      <td>His frens go then he in lor. Not alone wif my ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1045 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "0         0                Dude how do you like the buff wind.\n",
       "1         0  Tessy..pls do me a favor. Pls convey my birthd...\n",
       "2         1  Reminder: You have not downloaded the content ...\n",
       "3         1  Got what it takes 2 take part in the WRC Rally...\n",
       "4         1  Shop till u Drop, IS IT YOU, either 10K, 5K, £...\n",
       "...     ...                                                ...\n",
       "1040      1  4mths half price Orange line rental & latest c...\n",
       "1041      1  Thanks for the Vote. Now sing along with the s...\n",
       "1042      1  IMPORTANT INFORMATION 4 ORANGE USER 0796XXXXXX...\n",
       "1043      1  Urgent! call 09066612661 from landline. Your c...\n",
       "1044      0  His frens go then he in lor. Not alone wif my ...\n",
       "\n",
       "[1045 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataset as CSV files so we can reuse it later\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating data loaders\n",
    "\n",
    "To batch the messages we have 2 primary options:\n",
    "- Truncate all messages to the length of the shortest message in the dataset or batch\n",
    "- Pad all messages to the length of the longest message in the dataset or batch\n",
    "\n",
    "To implement batching, where all messages are padded to the length of the longest message in the dataset, we add padding tokens to all shorter messages. For this purpose, we use `<|endoftext|>` as a padding token\n",
    "\n",
    "However, instead of appending the string `<|endoftext|>` to each of the text messages directly, we can add the token ID corresponding to `<|endoftext|>` to the encoded text messages. 50257 is the token ID of the padding token `<|endoftext|>`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None,\n",
    "                 pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * \n",
    "            (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch, in train_loader:\n",
    "    pass\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions:\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\" : 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from chapter_04 import GPTModel\n",
    "from chapter_05 import load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size, models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from chapter_04 import generate_text_simple\n",
    "from chapter_05 import text_to_token_ids, token_ids_to_text\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a classification head\n",
    "\n",
    "We must modify the pretrained LLM to prepare it for classification fine-tuning. To do so, we replace the original output layer, which maps the hidden representation to a vocabulary of 50,257 , with a smaller output layer that maps to 2 classes: `0` (\"not spam\") and `1` (\"spam\"). We use the same model as beforem except we replace the output layer\n",
    "\n",
    "![fine-tuning](fine_tuning.png)\n",
    "\n",
    "\n",
    "Since we start with a pretrained model, it's not necessary to fine-tune all model layers. In NN-bases LMs, the lower layers generally capture basic language structures and semantics applicable across a wide range of tasks and datasets. So, fine-tuning only the last layers (i.e, layers near the output) which are more specific to nuanced linguistic patterns and task-specific features, is often sufficient to adapt the model to new tasks. \n",
    "A nice side effect is that it is computationally more efficient to fine-tune only a small number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the model ready for classification fine-tuning, we first FREEZE the model, meaning that we make all layers nontrainable\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we replace the output layer (model.out_head) which originally maps the layer inputs to 50,257 dimensions, the size of the vocabulary\n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(\n",
    "    in_features=BASE_CONFIG[\"emb_dim\"],\n",
    "    out_features=num_classes\n",
    ")\n",
    "# this new layer has its `requires_grad` attribute set to `True` by default, which means that it's the only layer in the model that will be updated during training. fine-tuning additional layers can noticeably improve the predictive performance of the model\n",
    "# We also configure the last transformer block and the final `LayerNorm` module, which connects this block to the output layer, to be trainable\n",
    "\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\" , outputs[:,-1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the causal attention mask setup, the last token in a sequence accumulates the most information since it is the only token with access to data form all previous tokens. Therefore, in our spam classification task, we focus on this last token during the fine-tuning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the classification loss and accuracy\n",
    "\n",
    "We must implement the model evalutation functions during the fine-tuning\n",
    "We previously computed the token ID of the next token generated by the LLM by converting the 50,257 outputs into probabilities via the softmax function and then returning the position of the highest probability via the argmax function\n",
    "\n",
    "We take the same approach here to calculate whether the model outputs a \"spam\" or \"not spam\" prediction for a given input. The only difference is that we work with 2-dim instead of 50,257-dim outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "    \n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch = input_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (\n",
    "                (predicted_labels == target_batch).sum().item()\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(\n",
    "    train_loader, model, device, num_batches=10\n",
    ")\n",
    "val_accuracy = calc_accuracy_loader(\n",
    "    val_loader, model, device, num_batches=10\n",
    ")\n",
    "test_accuracy = calc_accuracy_loader(\n",
    "    test_loader, model, device, num_batches=10\n",
    ")\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before fine-tuning the model we must define the loss function we'll optimize during training. Our objective is to maximize the spam classification accuracy of the model, which means that the preceding code should output the correct class labels\n",
    "\n",
    "Because classification accuracy is not a differentiable function, we use cross-entropy loss as a proxy to maximize accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss\n",
    "        else: \n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=5\n",
    "    )\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune the model on supervised data\n",
    "\n",
    "The training loop is the same we used for pretraining; the only difference is that we calculate the classification accuracy instead of generating a sample text to evaluate the model\n",
    "\n",
    "It also mirrors the `train_model_simple` function used for pretraining the model\n",
    "The only 2 distinctions are that we now track the nb of training examples seen instead of nb of tokens and we calculate the accuracy after each epoch instead of printing a sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter):\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "            \n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch + 1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                      )\n",
    "                \n",
    "        train_accuracy = calc_accuracy_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter)\n",
    "        \n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "    \n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 1.977, Val loss 2.196\n",
      "Ep 1 (Step 000050): Train loss 0.615, Val loss 0.636\n",
      "Ep 1 (Step 000100): Train loss 0.520, Val loss 0.555\n",
      "Training accuracy: 70.00\n",
      "Validation accuracy: 72.50\n",
      "Ep 2 (Step 000150): Train loss 0.563, Val loss 0.488\n",
      "Ep 2 (Step 000200): Train loss 0.418, Val loss 0.395\n",
      "Ep 2 (Step 000250): Train loss 0.408, Val loss 0.352\n",
      "Training accuracy: 82.50\n",
      "Validation accuracy: 85.00\n",
      "Ep 3 (Step 000300): Train loss 0.330, Val loss 0.314\n",
      "Ep 3 (Step 000350): Train loss 0.278, Val loss 0.181\n",
      "Training accuracy: 90.00\n",
      "Validation accuracy: 92.50\n",
      "Ep 4 (Step 000400): Train loss 0.076, Val loss 0.131\n",
      "Ep 4 (Step 000450): Train loss 0.125, Val loss 0.099\n",
      "Ep 4 (Step 000500): Train loss 0.202, Val loss 0.102\n",
      "Training accuracy: 100.00\n",
      "Validation accuracy: 97.50\n",
      "Ep 5 (Step 000550): Train loss 0.206, Val loss 0.110\n",
      "Ep 5 (Step 000600): Train loss 0.067, Val loss 0.056\n",
      "Training accuracy: 100.00\n",
      "Validation accuracy: 97.50\n",
      "Training completed in 4.65 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 5\n",
    "\n",
    "train_losses, val_losses, train_accs, val_accs, example_seen = \\\n",
    "    train_classifier_simple(model, train_loader, val_loader, optimizer, device, \n",
    "                            num_epochs, eval_freq=50, eval_iter=5)\n",
    "    \n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(\n",
    "    epochs_seen, example_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    \n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "    \n",
    "    \n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(example_seen, train_values, alpha=0)\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n",
    "    \n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, example_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor,examples_seen_tensor,train_losses, val_losses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, example_seen, len(train_accs))\n",
    "\n",
    "plot_values(\n",
    "    epochs_tensor, examples_seen_tensor, train_accs, val_accs,\n",
    "    label=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.60%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 96.00%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(\n",
    "        text, model, tokenizer, device, max_length=None,\n",
    "        pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[1]\n",
    "\n",
    "    input_ids = input_ids[:min(\n",
    "        max_length, supported_context_length\n",
    "    )]\n",
    "\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "\n",
    "    input_tensor = torch.tensor(\n",
    "        input_ids, device=device\n",
    "    ).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know and I will give you 10000$!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8n/tlk756jx44lbb6m66gsbw03m0000gn/T/ipykernel_74151/3769342537.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(\"review_classifier.pth, map_location=device\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'review_classifier.pth, map_location=device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_state_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mreview_classifier.pth, map_location=device\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(model_state_dict)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m   1063\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m-> 1065\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m   1066\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1067\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    467\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 468\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    469\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 449\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'review_classifier.pth, map_location=device'"
     ]
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth, map_location=device\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
